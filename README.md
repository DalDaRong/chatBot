# 감성분석 기반 심리상담 AI 챗봇
**"일상이 된 비대면…소통부재·고립"**

코로나19 사태의 장기화, 거리두기의 일상화로 재택근무와 원격수업 등이 일상으로 자리 잡았습니다.   
2022년에는 비대면 문화에 기반한 서비스가 훨씬 세련되고 정교화될 것이지만, 이런 상황이 불러올 부작용으로 대면 소통이 줄면서 사회 전체가 움츠러들고 사람들이 고립되어간다 생각했습니다. 

## 목적
코로나 사태로 사람을 못만나면서 우울감이 늘어나고있습니다. 우울감은 챗봇으로도 급감한다는 결과의 기사를 접했습니다. 그래서 사용자의 감정을 인식해 상호작용을 하는 챗봇 프로젝트를 진행했습니다

보통 챗봇 심리상담으로 얻을 수 있는 기대효과는 아래와 같습니다. 
- 좋은 접근성, 24시간연결
- 비대면
- 장기적으로 비용절감

이러한 이점에도 불구하고 현재 소비자가 챗봇에 만족하지 못한 이유를 알아보았습니다 (출처 챗봇 소비자 만족도, Spicesworks)   
<img src="https://user-images.githubusercontent.com/97740175/173789066-ec6c3ed4-c590-4fe8-8408-7a493315c808.png" width="60%" height="60%"></img>
1. 챗봇이 대화의 맥락을 파악하지 못함
2. 입력한 내용을 이해하지 못함
3. 명령 수행이 부적절함

이런 문제에 직면했을때 소비자가 챗봇 서비스를 이용하기를 포기한다는 점을 눈여겨보고, 이러한 부분을 개선하기위해 아래의 3가지를 목표로 진행했습니다.   
1. GPT-2 모델을 사용하여, 고정되지 않은 다양한 형태의 문장 생성.   
2. BERT 모델을 사용하여, **문장 맥락 파악**과 사용자 특징, 감정, 상황 등을 반영.   
3. Q,A,Q형식으로 대화 내용을 기억하여 맥락파악   


## 기간
2021.03.31 - 2021.05.19 (8 주)


## 팀 구성
본인 외 2인

## 팀 내 역할
Python을 활용한 데이터 결측치 처리, 라벨 정수화   
훈련된 BERT모델을 사용하여 스코어 출력 기능 구현   
GPT모델로 생성된 문장 중 길이제한으로 미완성 문장 제거 기능 구현   
사용자의 말투가 섞여서 생성된 경우, 케이스에 따라 문장 부분 삭제 기능 구현   
입력문장에 구두점이 없을 경우, 끝에 "." 붙여서 전달하는 기능 구현   
대화를 Q+A+Q 형식으로 저장하며 이전 대화 반영 기능 구현   


## 사용 기술
python, koGPT-2, klueBERT, streamlit


## 개발 과정 
- 앞서 진행한 3개의 프로젝트와 다르게 마지막 프로젝트는 처음 진행한 장기 프로젝트로, 하루하루 일정을 기록하고 전체를 관리하며 진행했습니다.   
<img src="https://user-images.githubusercontent.com/97740175/173689837-329990e9-6eec-4dbb-ba8d-0472862c8dbc.png" width="90%" height="90%"></img>

### 데이터 분석



### 모델
#### 사용모델
> **GPT모델**    
> <img src="https://user-images.githubusercontent.com/97740175/173801316-e5273ee5-f34c-437c-b6e7-a6dbdbb00ff4.png" width="40%" height="40%"></img>   
> - 디코더를 활용하여 순차적 단어를 생성하는 모델입니다.
> - 챗봇의 다양한 대답 생성을 위해 사용하였습니다.
>
>##### KoGPT2 (skt/kogpt2-base-v2)
>skt/kogpt2-base-v2모델을 pretrained하여 사용하였습니다.   
>데이터를 Q(사용자의말)와 A(대답)형태로 하여, 훈련시켜 들어온 문장 뒤에 대답이 생성되도록 학습시켰습니다.     
>이과정에서, 학습되는 기존의 감성대화 말뭉치는 너무 경직된 말투라 생각되어 학습 데이터 셋에 웰니스 대화 스크립트 추가로 말투 개선을 의도했습니다.   
><img src="https://user-images.githubusercontent.com/97740175/173804067-fecef858-9b84-44f1-b299-dc182764de3d.png" width="42%" height="42%"></img>    
>자연어 생성 모델이기에 정답이 없어 Accuracy측정은 못하였기에, 직접 검증을 후반에 했습니다.

</br>


> **BERT 모델**   
> <img src="https://user-images.githubusercontent.com/97740175/173801334-9d14a710-84d6-4003-87c8-72bf2c5418f5.png" width="40%" height="40%"></img>   
> - 인코더를 활용하여 양방향분석을 하는 모델입니다.
> - 생성된 문장의 분류를 위해 사용하였습니다.
>
>##### KlueBERT (klue/bert-base)
>klue/bert-base모델을 pretrained하여 사용하였습니다.   
>데이터는 카테고리 분류가 된 감성대화 말뭉치만 사용하였습니다.
>Q와, Q+A를 입력으로 하여 카테고리를 예측하는 형태로 모델을 훈련시켰습니다. y는 각 카테고리에 대한 85개의 스코어값입니다.    
><img src="https://user-images.githubusercontent.com/97740175/173806997-99e07b47-8568-4129-a693-a62735f91001.png" width="60%" height="60%"></img>    
>들어온 X(문장)을 6개 카테고리(하위 총 85개)로 분류, y와의 유사도를 통해 스코어를 계산합니다.    
>각 6개 카테고리에대한 Accuracy :    
><img src="https://user-images.githubusercontent.com/97740175/173806542-5830d553-7fa0-41ac-aa49-004f8f5badeb.png" width="70%" height="70%"></img> 


#### 모델 구조도
<img src="https://user-images.githubusercontent.com/97740175/173807655-c28376da-436f-40a0-aac8-299935ce82da.png" width="70%" height="70%"></img>    
1. 입력된 user text에 문장구분을 위한 토큰\<user>,\<sys>을 붙여 GPT-2 모델로 문장을 생성합니다. \<user>은 문장의 시작을, \<sys>끝을 표시하고 gpt모델은 \<sys>에 이어지는 문장을 생성합니다.
2. GPT-2모델에서 10개의 문장을 랜덤으로 생성합니다
3. 생성된 10개의 문장은 BERT모델로 라벨에 대한 각각 스코어 점수를 갖습니다.
4. 10문장에 대한 10개의 스코어 점수에 유사도 측정으로 가장 높은 점수를 받은 문장을 선택하여 후처리 후, 출력합니다.

#### 모듈 구조도

#### 모델 성능비교
모델의 성능을 평가하기위한 두가지의 데이터셋을 만들었습니다.   
- **test set 1** = 에폭, wellness 추가, 가중치 등의 변수를 비교하기 위해 사용한 데이터.   
  - 감성대화말뭉치(50), 웰니스데이터(50), 인상한말(30), 감성대화에 없는 새로 만든 말(30)으로 총 입력문장 160개
- **test set 2**  = 대화 저장 유무와  방식에 따른 성능을 비교하기 위해 만든 데이터. 
  - 감성대화 말뭉치 데이터 속 네번의 연속된 대화가 이루어진 50개의 케이스
  - 50개의 대화 케이스를 9종류의 대화저장 형태에 따라 데이터셋으로 만들었습니다.

- (1)	Epoch(E),  wellness(\_well) 유무


### 쳇봇시연


### 서비스확장






# 감성분석 기반 심리상담 AI 챗봇
**"일상이 된 비대면…소통부재·고립"**

코로나19 사태의 장기화, 거리두기의 일상화로 재택근무와 원격수업 등이 일상으로 자리 잡았습니다.   
2022년에는 비대면 문화에 기반한 서비스가 훨씬 세련되고 정교화될 것이지만, 이런 상황이 불러올 부작용으로 대면 소통이 줄면서 사회 전체가 움츠러들고 사람들이 고립되어간다 생각해습니다. 

## 목적
코로나 사태로 사람을 못만나면서 우울감이 늘어나고있습니다. 우울감은 챗봇으로도 급감한다는 결과의 기사를 접했습니다. 그래서 사용자의 감정을 인식해 상호작용을 하는 챗봇 프로젝트를 진행했습니다

보통 챗봇 심리상담으로 얻을 수 있는 기대효과는   
- 좋은 접근성, 24시간연결
- 비대면
- 장기적으로 비용절감

이러한 이유들에도 불구하고 현재, 소비자가 챗봇에 만족하지 못한 이유를 알아보았습니다 (출처 챗봇 소비자 만족도, Spicesworks)   
<img src="https://user-images.githubusercontent.com/97740175/173789066-ec6c3ed4-c590-4fe8-8408-7a493315c808.png" width="60%" height="60%"></img>


그래서 이러한 부분을 반영하기위해 아래의 3가지를 목표로 진행했습니다.   
1. GPT-2 모델을 사용하여, 고정되지 않은 다양한 형태의 문장 생성.   
2. BERT 모델을 사용하여, **문장 맥락 파악**과 사용자 특징, 감정, 상황 등을 반영.   
3. Q,A,Q형식으로 대화 내용을 기억하여 맥락파악   



## 기간
2021.03.31 - 2021.05.19 (8 주)


## 팀 구성
본인 외 2인

## 팀 내 역할
Python을 활용한 데이터 결측치 처리, 라벨 정수화   
훈련된 BERT모델을 사용하여 스코어 출력 기능 구현   
GPT모델로 생성된 문장 중 길이제한으로 미완성 문장 제거 기능 구현   
사용자의 말투가 섞여서 생성된 경우, 케이스에 따라 문장 부분 삭제 기능 구현   
입력문장에 구두점이 없을 경우, 끝에 "." 붙여서 전달하는 기능 구현   
대화를 Q+A+Q 형식으로 저장하며 이전 대화 반영 기능 구현   


## 사용 기술
python, koGPT-2, klueBERT, streamlit


## 개발 과정 
- 앞서 진행한 3개의 프로젝트와 다르게 마지막 프로젝트는 처음 진행한 장기 프로젝트로, 하루하루 일정을 기록하고 전체를 관리하며 진행했습니다.   
<img src="https://user-images.githubusercontent.com/97740175/173689837-329990e9-6eec-4dbb-ba8d-0472862c8dbc.png" width="90%" height="90%"></img>

### 데이터 분석

#### 데이터 소개

1. 감성대화 말뭉치 데이터 (AIhub 2021.06)
* 27만개의 말뭉치 데이터는 주로 우울증 관련 언어로 이루어져있습니다. 최대 4번의 연속적인 대화가 이어집니다. 
* 분류에 특화되어있습니다. 4개의 연령, 성별, 12개의 상황키워드, 3개의 만성질환, 6개의 감정 대분류로 분류되어있습니다. 6개의 감정 대분류는 하위 58가지 감정 소분류로 다시 분류됩니다.

<img src="https://user-images.githubusercontent.com/96275852/173796803-1460ff68-8985-429a-b78c-0a67e66a880b.png" width="100%" height="100%">

2. 웰니스 대화 스크립트
* 세브란스 상담 데이터를 기반으로 구축한 정신 상담 데이터셋입니다.
* 359개 대화의도에 대한 5,232개 사용자 발화와 1,023개 챗봇 발화로 이루어져있습니다.
* 이 데이터는 보다 생동감 있는 챗봇 발화를 위해 GPT 모델 학습에만 추가했습니다.
<img src="https://user-images.githubusercontent.com/96275852/173799606-fc0a5180-e53b-4c34-9fb4-060e3b302cc1.png" width="100%" height="100%">

#### 데이터 전처리

<img src="https://user-images.githubusercontent.com/96275852/173795115-7723b301-d863-4c92-9462-7a0a0b9be8ea.png" width="70%" height="70%">

##### 정수화
BERT 모델 학습을 위한 라벨링을 진행했습니다.  
4개의 연령, 성별, 12개의 상황키워드, 3개의 신체질환, 6개의 감정 대분류, 하위 58가지 감정 소분류를 라벨링했습니다.

```
labeling_cols = ['연령', '성별', '상황키워드', '신체질환', '감정_대분류',	'감정_소분류']
for label in labeling_col:
  temp_list = []
  temp_list = all_df2[label].unique().tolist()  # 임시 리스트에 고유값 넣기
  all_df2[label] = all_df2[label].map(lambda x :temp_list.index(x)) # 정수화
```
##### 결측치 제거
짝이 맞지 않는 문장은 결측처리 했습니다.

```
# 발화만있고 응답이 없거나 발화는 없는데 응답만 있는 대화쌍의 조건
Nan_cond = all_df2['사람문장4'].isnull() != all_df2['시스템응답4'].isnull()

# 조건이 해당되는 사람문장4를 Nan처리
all_df2.loc[(Nan_cond),'사람문장4'] = np.nan
all_df2.loc[(Nan_cond),'시스템응답4'] = np.nan
```
##### QAQ 합치기
*편의를 위해 사람문장은 Q, 시스템응답은 A로 표기하겠습니다.*
최대 4번 연속되는 사용자와 챗봇의 대화를 아래와 같은 형태로 변경해주었습니다. 데이터 형태를 변경해줌으로써 이전에 챗봇과 나눈 대화 내용을 기억하게해, 대화에 연속성을 반영할 수 있습니다. 
<img src="https://user-images.githubusercontent.com/96275852/173801308-a4ce5fdc-3786-45e7-9d58-3ea65f92264f.png" width="50%" height="50%">

##### 토큰 삽입
QA를 구분하기 위해 둘 사이에 [SEP]토큰을 삽입합니다. BERT에 내장된 토큰과 동일한 토큰입니다.

##### 데이터 추가
보다 나은 성능을 위해 데이터를 추가했습니다. 두가지 모델의 용도에 맞게 데이터를 다르게 추가했습니다. 

* GPT 모델 : 문장 생성 모델입니다. 보다 생동감 있는 답변을 위해 웰니스 대화 스크립트를 추가했습니다.
* BERT 모델 : 분류를 위한 모델입니다. A 데이터는 Q와 동일한 라벨링이 되어있습니다. df에 Q+A열을 추가로 만들어 학습 데이터를 2배로 만들었습니다. Q와 Q+A열을 모두 학습시킴으로써 모델의 분류 성능을 높였습니다.
```
df['QnA'] = df['Q'] + ' [SEP] ' + df['A']
```

### 모델 

### 챗봇시연

https://user-images.githubusercontent.com/96275852/173808182-c60d4aaf-bc31-430a-984b-6c5ae3776dfb.mp4
Streamlit을 사용해 서비스를 구현 했습니다. 청소년이 챗봇 상담을 한다는 가정 하에 대화 내용을 구성했습니다. 챗봇이 사용자의 감정과 상황에 적합한 답변을 하고있음을 볼 수 있습니다. (배속을 한 상태입니다.)

### 서비스확장

### 회고
- 데이터를 제공하는 AIhub에는 분류 기준이 명확하게 기재되어있지 않았습니다. 의미 중첩으로 보이는 클래스들이 있었지만, 임의로 데이터를 수정하기에는 데이터의 변별력을 잃게될 것 같아 조심스러웠습니다. 감성말뭉치 데이터에서 이 부분을 명확히 확인하지 못한 점이 아쉽습니다.
- 다중 분류를 위한 BERT모델 선정하는 작업과 성능 비교를 위한 테스트 작업에서 많은 시간이 소요되었습니다. 시간 부족으로 인해 버트 분류에서 유사도를 계산 가중치를 다양하게 테스트 해보지 못해 아쉽습니다.
- GPU가 없는 개인 컴퓨터에서 구동하기엔 속도가 느립니다. 챗봇 볼륨이 클수록 원활한 구동을 위해서 고사양의 서버가 필요한데, 시중의 챗봇 볼륨이 작은 이유도 고사양 서버를 빌리는데 드는 비용이 상당하기 때문이라는 피드백을 받았습니다. 다음 작업에는 보다 시장성을 고려한 챗봇도 개발해보고 싶습니다. 
